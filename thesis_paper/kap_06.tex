\chapter{Results and Analysis}
\label{chap: default_emu}

In this chapter, we will discuss the performance of a two-emulator setup
built using the default configuration of CL: both the massless- and
massive-neutrino emulators appraised here use the COMET priors
(table~\ref{tab: COMET_priors}), $N_k = 300$, and $N_s = 3000$ for both the
training and testing data sets.

The final training LHS had an $s^*$ of 0.07972 in the massive case and 
0.02274 in the massless case. The final testing LHS had an $s^*$ of 0.07275 in 
the massive case and 0.02015 in the massless case. All numbers have been 
rounded to four significant figures.

\section{Quantifying the Performance of the Emulator}

To evaluate the performance of the emulator, we use the testing pipeline
explained in chapters~\ref{chap: emu_outline} and~\ref{chap: implementation}.
That is, we create an LHS of test cosmologies, which the training stages have
never seen, and compare the output of the emulator object to that of
CAMB. As in neural network contexts, GPR performance is typically evaluated
using test sets (\citealp{Mancini}, \citealp{Arico}, and
\citealp{Eggemeier}).\footnote{However, these test sets are
more commonly referred to as ``validation sets.'' We use the phrase
``test set'' to call to mind the three conventional data sets in a machine
learning setup: training, validation, and testing. This distinction will
prove useful in section~\ref{sec: future_work}.}

We appreciate that appraisal based on test sets
may not provide hard boundaries on the true
range of errors associated with the emulators,
because the continuity of the parameter hypervolume means that an infinite
number of cosmologies could be tested. Therefore, traditional
goodness-of-fit tests such as $\chi^2$ do not apply here.
However, precisely because
power spectra vary smoothly in this space\footnote{Indeed, without this
property, interpolation would be unproductive.}, we expect the error 
curves to vary similarly. So long as the test LHS represents a reasonable
coverage of the parameter space, we expect the errors calculated therefrom to
be similarly representative of emulator performance. On the other
hand, at the edges of the parameter space, where interpolation begins to
break down, the errors will be at their highest, and the following analyses
may not be representative of these edge cases.

For this chapter as well as chapter~\ref{chap: disc_and_conc}, we will focus
on just two error metrics: percent error and squared error. We include percent
error as it is more common in the literature and because it is immediately
interpretable (\citealp{Mancini}, \citealp{Arico}, and
\citealp{Eggemeier}). By contrast, the squared errors are difficult to
understand unless compared across multiple similar cases.
Nevertheless, we argue
that squared errors represent a more useful metric, at least within a single
paper, because they are unbiased with respect to the magnitude of the emulated
quantity. Consider that $P(k)$ is smallest at the largest $k$; if an emulator
mispredicts $P(k)$ with a constant offset, then the percent error curves will
be largest at the smallest $k$. As a further example, consider that the
overall amplitude of $P(k)$ is smaller for smaller $\tilde{\sigma_{12}}$;
if we again imagine a constant offset, $\tilde{\sigma_{12}}$ will appear as a
problematic parameter if we look only at percent error.


\section{Percent and Square Errors on Random Cosmologies}

This will be a fairly short section, basically just showing the plot of 5000 
error curves in these two ways. I may focus in on different k-ranges, but the 
error curves are currently quite flat, so I don't think that would be a good 
use of space.

Furthermore, I will try to select a couple of cosmologies out of the 5000 
(maybe a low-error case and a high-error case) as examples of the performance 
on just one at a time. But I'm not sure how insightful that will be, I don't 
know if that will tell the reader a whole lot.

\textcolor{green}{redo the numbers in this next paragraph}

The current state of the massless-neutrino emulator features sub-0.1\% error 
for the vast majority of scales, with the exception of some wild fluctuations  
between k=0.09 and 0.2 / Mpc. Outside of this range, the errors tend to 
sub-0.01\% in the large-scale regime and sub-0.005\% in the small-scale 
regime. Please refer to figures XXX through XXX for illustrations thereof.


\section{Performance in Different Parameters}

Here, I will either include color plots or, as Dante suggests, monochrome 
plots with error as one axis and parameter value as the other (i.e. $k$ 
fixed). Then, if I haven't tightened the $\sigma_{12}$ performance by the time 
of submission, I can talk about how this is the most promising avenue for 
refinement of the emulator. In any case, I plan to spend some time talking 
about \textit{why} parameter x is the current biggest problem for the 
emulator. 


\section{Improvement from Two-emulator Solution}
\label{sec: 2emu_improvement}

To justify our decision and to quantify the improvement from this approach, we
have prepared \textcolor{orange}{some} plots in
section~\ref{sec: 2emu_improvement}.

\textcolor{blue}{This will be an extremely short section with some error
plots of the massive-neutrino cosmology evaluating massless-neutrino
cosmologies.}