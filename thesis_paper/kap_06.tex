\chapter{Results and Analysis}
\label{chap: default_emu}

In this chapter, we will discuss the performance of a two-emulator setup
built using the default configuration of CL: both the massless- and
massive-neutrino emulators appraised here use the COMET priors
(table~\ref{tab: COMET_priors}), $N_k = 300$, and $N_s = 3000$ for both the
training and testing data sets.

The final training LHS had an $s^*$ of 0.07972 in the massive case and 
0.02274 in the massless case. The final testing LHS had an $s^*$ of 0.07275 in 
the massive case and 0.02015 in the massless case. All numbers have been 
rounded to four significant figures.

\section{Quantifying the Performance of the Emulator}

To evaluate the performance of the emulator, we use the testing pipeline
explained in chapters~\ref{chap: emu_outline} and~\ref{chap: implementation}.
That is, we create an LHS of test cosmologies, which the training stages have
never seen, and compare the output of the emulator object to that of
CAMB. As in neural network contexts, GPR performance is typically evaluated
using test sets (\citealp{Mancini}, \citealp{Arico}, and
\citealp{Eggemeier}).\footnote{However, these test sets are
more commonly referred to as ``validation sets.'' We use the phrase
``test set'' to call to mind the three conventional data sets in a machine
learning setup: training, validation, and testing. This distinction will
prove useful in section~\ref{sec: future_work}.}

We appreciate that appraisal based on test sets
may not provide hard boundaries on the true
range of errors associated with the emulators,
because the continuity of the parameter hypervolume means that an infinite
number of cosmologies could be tested. Therefore, traditional
goodness-of-fit tests such as $\chi^2$ do not apply here.
However, precisely because
power spectra vary smoothly in this space\footnote{Indeed, without this
property, interpolation would be unproductive.}, we expect the error 
curves to vary similarly. So long as the test LHS represents a reasonable
coverage of the parameter space, we expect the errors calculated therefrom to
be similarly representative of emulator performance. On the other
hand, at the edges of the parameter space, where interpolation begins to
break down, the errors will be at their highest, and the following analyses
may not be representative of these edge cases.

For this chapter as well as chapter~\ref{chap: disc_and_conc}, we will focus
on just two error metrics: percent error and squared error. We include percent
error as it is more common in the literature and because it is immediately
interpretable (\citealp{Mancini}, \citealp{Arico}, and
\citealp{Eggemeier}). By contrast, the squared errors are difficult to
understand unless compared across multiple similar cases.
Nevertheless, we argue
that squared errors represent a more useful metric, at least within a single
paper, because they are unbiased with respect to the magnitude of the emulated
quantity. Consider that $P(k)$ is smallest at the largest $k$; if an emulator
mispredicts $P(k)$ with a constant offset, then the percent error curves will
be largest at the smallest $k$. As a further example, consider that the
overall amplitude of $P(k)$ is smaller for smaller $\tilde{\sigma_{12}}$;
if we again imagine a constant offset, $\tilde{\sigma_{12}}$ will appear as a
problematic parameter if we look only at percent error.


\section{Percent and Square Errors on Random Cosmologies}

* Percent error curves massless
* Squared error curves massless
* Percent error curves massive
* Squared error curves massive

This will be a fairly short section, basically just showing the plot of 5000 
error curves in these two ways.

\textcolor{orange}{Create some plots focusing on the BAO error spikes? i.e.
zoom-in on k-ranges.}

\textcolor{green}{redo the numbers in this next paragraph}

The current state of the massless-neutrino emulator features sub-0.1\% error 
for the vast majority of scales, with the exception of some wild fluctuations  
between k=0.09 and 0.2 / Mpc. Outside of this range, the errors tend to 
sub-0.01\% in the large-scale regime and sub-0.005\% in the small-scale 
regime. Please refer to figures XXX through XXX for illustrations thereof.

As we can see from figures~\ref{fig: massless_default} 
and~\ref{massive_default}, both emulators are most accurate at very large and
very small $k$, with significant difficulties around the BAO region. We
consider the small-scale performance a powerful confirmation of our
techniques, as the impact of massive neutrinos is most significant at small
scales.

We highlight that the massive emulator
performs significantly worse than its massless counterpart. We attribute this
discrepancy to the results of section~\ref{sec: fit_testing}, which indicate
that evolution parameters besides $A_s$ are necessary for complete
characterization of the impact of massive neutrinos. Nevertheless, the
overall percent error of the massive emulator is \textcolor{green}{nearly}
at the level of CAMB itself, so we consider the massless emulator an
encouraging success.

As evolution-mapping emulation for \textit{massive}-neutrino cosmologies
is the novel feature of this work, we will henceforth concentrate exclusively
on the massive-neutrino emulator.

\section{Performance in Different Parameters}
\label{sec: param_breakdown}

In this section, we will break down the performance of the emulator
by coloring
the same error plots as before (figure~\ref{fig: massive_default})
according to different parameters.

Here, I will either include color plots or, as Dante suggests, monochrome 
plots with error as one axis and parameter value as the other (i.e. $k$ 
fixed). Then, if I haven't tightened the $\sigma_{12}$ performance by the time 
of submission, I can talk about how this is the most promising avenue for 
refinement of the emulator.

\textcolor{orange}{I plan to spend some time talking 
about \textit{why} parameter x is the current biggest problem for the 
emulator.}

\textcolor{orange}{It would have been nice if you had done like Andrea said,
and produced a plot colored by the ``extremeness'' of the parameters. We
could implement an extremeness index for parameter $x$ simply by taking
subtracting 0.5 and taking the absolute value, assuming that $x$ comes from
the unit LHS. Then, we could take the average over six parameters to get
an extremeness index for the cosmology as a whole. Optionally, for plot
optimization, you could multiply the final value by 2 so that the extremeness
runs from 0 to 1.}


\section{Improvement from Two-emulator Solution}
\label{sec: 2emu_improvement}

To justify our decision and to quantify the improvement from this approach, we
have prepared \textcolor{orange}{some} plots in
section~\ref{sec: 2emu_improvement}.

\textcolor{blue}{This will be an extremely short section with some error
plots of the massive-neutrino cosmology evaluating massless-neutrino
cosmologies.}