\chapter{Conceptual Outline of Our Emulator Code and Pipeline}

\textcolor{blue}{The point of this section is to introduce the reader to the
basic structure of the emulator pipeline. Most of the discussion will follow
from a flow chart showing the various conceptual pieces of the emulator. Also
in this section, I will introduce various choices made (e.g. 5000 training
spectra, 300 points for each spectrum) WITHOUT justifying any of them--later,
in chapter~\ref{chap: disc_and_conc}, we'll justify these decisions and
talk about the consequences of alternate settings.}

In order to simplify the process of testing different emulator setups, and to make power
spectra more accessible to beginners in the field, we have developed a Python package,
which we call Cassandra-Linear (CL)1. CL represents a full emulation pipeline from the
generation of training and testing data to the plotting of error statistics associated with
the emulation.

% We're gonna need a flow chart for this puppy. That should be priority number
% one, because the writing should constantly refer back to it.

\section{Design Choices}

By default, each Latin hypercube consists of $N_s = 5000$ entries. For 
justification of this quantity, please refer to
section~\ref{sec: num_samples}.

$N_k = 300$.

\section{Creation of Separate Emulators}
\label{sec: 2emu_intro}

This is a brief introductory section motivating the creation of two emulators:
unlike the other five parameters, the physical density in massive neutrinos 
has a hard lower bound. This creates some minor regression problems (appeal to 
boundary effects / danger of extrapolation).

To simplify the user experience, this two-emulator solution lives ``under the
hood'' and by default \textcolor{orange}{will be} hidden behind an interface
which automatically queries the correct emulator given some user-input
cosmology.

To justify our decision and to quantify the improvement from this approach, we
have prepared \textcolor{orange}{some} plots in section~\ref{sec: 2emu_improvement}.

\textcolor{orange}{Conclude this section by saying that this integration of multiple emulators into one user-facing script can be further exploited with, for example, different emulators for different neutrino mass hierarchies.}

\section{Unit LHCs}
\label{sec: lhc_flow_chart}

The \verb|pyDOE2| function that we will use to generate our LHCs
returns a result with entries that range from zero to unity. These unit LHCs
will eventually be used to create a set of cosmological
configurations which will act as the $X$ data set when we train our emulator.

In order to these LHC entries into cosmological parameters that we can input 
into CAMB, we will need to rescale them with our priors for each parameter.
However, instead of rescaling immediately, we will rescale later: 
\textcolor{orange}{The benefits of rescaling later are. This is useful not
just for changing priors but even for changing the way that we sample a
particular prior (for example, $\sigma_{12}^2$ sampling--although we did not
get it to work, the infrastructure is still there for whoever comes along in
the future.}
 
We describe the building of the unit LHC in section~\ref{sec: build_lhc}
and its rescaling (as well as the construction of the $Y$ data set) 
in~\ref{sec: generate_emu_data}.


\section{Default Priors}
\label{sec: default_priors}

% One reason this goes here: priors show up in almost every script,
% so there isn't a great cass-L section in which to put this.

As we will explain in section~\ref{sec: build_lhc}, our code generates unit 
Latin hypercube samples so that a single hypercube can be used to build 
several different emulators simply by using a different set of priors to 
rescale the cube.

CL is packaged with three pairs of prior files. Depending on which priors the user selects,
the emulator will automatically become a massive-neutrino or massless-neutrino emulator.
\textcolor{orange}{This needs to be linked to the convenience section, on how to add scenario files and what
not. But this feature is not finished yet! We may have to punt it to “future work.”}

\textcolor{orange}{Table goes here.}

In tables XXX-XXZ, we provide the specific upper and lower bounds for each of
the six cosmological parameters over which our massive-neutrino emulator is 
trained. All intervals are sampled uniformly, \textcolor{orange}{Although some
experimental code exists to interpret the same hypercube as a uniform sampling
in root or square space, for example}. The ``MEGA'' priors 
(table~\ref{tab: priors}) represent the original goal for this project, which 
unfortunately suffered from too many unsolvable cells. In
section~\ref{sec: generate_emu_data}, we will describe what it means for a 
cell to be unsolvable.

The priors that we use correspond to those currently used by COMET. \textcolor{orange}{Should I spend any time defending this choice here, or should I put all of the defense in section~\ref{sec: priors}?}

The default priors that we use correspond to those currently used by COMET. \textcolor{orange}{Two
justifications for this choice: unsolvable cells, but more than that, simplicity and accuracy
for the ``demo'' run.}

\section{Emulation over Uncertainties}

For a further step of accuracy, we can add a third data set to our pipeline
and introduce a second layer of emulation.

Up to this point, our pipeline has included a training set and a testing set.
If we add a validation set, then we can train a second emulator over the
errors associated with the first emulator's performance on this validation
set.

Within the current (as of \textcolor{orange}{24.08.2023}) setup of
Cassandra-Linear, we typically generate two Latin hypercubes for each
emulator. The first represents our training set and an emulator cannot be
produced without it. The second one represents our validation set.

\textcolor{orange}{In a future
release of Cassandra-Linear, this set will be used to train an ``uncertainty''
emulator, which will train over the errors from the main emulator in order to
provide the user with an uncertainty estimate for any cosmology located within 
the space of priors over which the main emulator was trained.} 

\textcolor{orange}{However, this functionality has not yet been implemented. 
Currently, we are 
using the validation hypercube more as a test hypercube: we compute the uncertainties at discrete points and examine these uncertainties (e.g. with
scatterplots and histograms) to assess the performance of the emulator.}
