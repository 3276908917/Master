\chapter{Results and Analysis}
\label{chap: results}

In this chapter, we will discuss the performance of a two-emulator setup
built using the default configuration of CL: both the massless- and
massive-neutrino emulators appraised here use the COMET priors
(table~\ref{tab: COMET_priors}), $N_k = 300$, and $N_s = 3000$ for both the
training and testing data sets.

\section{Quantifying the Performance of the Emulator}

To evaluate the performance of the emulator, we use the testing pipeline
explained in section~\ref{sec: test_emu}.
That is, we create an LHS of test cosmologies, which the training stages have
never seen, and compare the output of the emulator object to that of
CAMB. As in neural network contexts, GPR performance is typically evaluated
using test sets (\citealp{Mancini}, \citealp{Arico}, and
\citealp{Eggemeier}).\footnote{However, these test sets are
more commonly referred to as ``validation sets.'' We use the phrase
``test set'' to call to mind the three conventional data sets in a machine
learning setup: training, validation, and testing. This distinction will
prove useful when we discuss the future direction of the code in
chapter~\ref{chap: conclusion}.}

We appreciate that appraisal based on test sets
may not provide hard boundaries on the true
range of errors associated with the emulators,
because the continuity of the parameter hypervolume means that an infinite
number of cosmologies could be tested. Therefore, traditional
goodness-of-fit tests such as $\chi^2$ do not apply here.
However, precisely because
power spectra vary smoothly in this space\footnote{Indeed, without this
property, interpolation would be unproductive.}, we expect the error 
curves to vary similarly. So long as the test LHS represents a reasonable
coverage of the parameter space, we expect the errors calculated therefrom to
be similarly representative of emulator performance. On the other
hand, at the edges of the parameter space, where interpolation begins to
break down, the errors will be at their highest, and the following analyses
may not be representative of these edge cases.

For this chapter, we will focus
on just two error metrics: percent error and absolute error, or the absolute
value of the difference between the predicted and CAMB-calculated $P_L(k)$. We include percent
error as it is more common in the literature and because it is immediately
interpretable (\citealp{Mancini}, \citealp{Arico}, and
\citealp{Eggemeier}). By contrast, the absolute errors are difficult to
understand unless compared across multiple similar cases.
Nevertheless, we argue
that absolute errors represent a more useful metric, at least within a single
paper, because they are unbiased with respect to the magnitude of the emulated
quantity. Consider that $P(k)$ is smallest at the largest $k$; if an emulator
mispredicts $P(k)$ with a constant offset, then the percent error curves will
be largest at the smallest $k$. As a further example, consider that the
overall amplitude of $P(k)$ is smaller for smaller $\tilde{\sigma}_{12}$;
if we again imagine a constant offset, $\tilde{\sigma}_{12}$ will appear as a
problematic parameter if we look only at percent error.


\section{Percent and Absolute Errors on Random Cosmologies}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=\textwidth]{error_on_emulators/def_massive_curves}
  \caption[Default Massive Emulator Error Curves]{5000 error curves provided 
  by running the test set through the emulator. The curves are colored
  according to their value in $\tilde{\sigma}_{12}$. The opacity of the curves
  allows us to conclude that the dynamic range, at least in the percent
  error case, is dominated by a small number of cosmologies.
  In absolute terms, the emulator
  clearly performs best on the small scales. In relative terms, the
  performance is best on large scales. Regardless of the metric used, the
  error is most extreme on medium scales, and drastic fluctuations can be seen 
  in the percent error plot.}
  \label{fig: def_massive_curves}
\end{figure}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=\textwidth]{error_on_emulators/def_massive_hist}
  \caption[Default Massive Emulator Error Histograms]{The left plot is a
    histogram of the medians of the absolute values of each difference curve.
    The right plot is a histogram of the maxima of the absolute values of
    each percent error curve. In both cases, we find the plots to have
    extremely long tails; we have assigned arbitrary right endpoints
    in order to focus on the central shape.}
  \label{fig: def_massive_hist}
\end{figure}

In figure~\ref{fig: def_massive_curves}, we 
show the performance of the default massive-neutrino emulator. We consider
the overall performance encouraging. Even the worst error curve, which
appears to have been the worst by far, did not exceed a 0.3\% error.
In the follow-up histograms (figure~\ref{fig: def_massive_hist}), we find
that in the vast majority of tested cosmologies, the error does not
exceed 0.04\%.

The curves of figure~\ref{fig: def_massive_curves} were colored according to
their values in $\tilde{\sigma_{12}}$, which we found was the only parameter
associated with a consistent trend. At large scales, lower values of
$\tilde{\sigma}_{12}$ are associated with higher percent errors. However, at
all scales, higher values of $\tilde{\sigma}_{12}$ are strongly tied to
increased absolute error.

The dramatic
oscillations around the BAO region suggest to us that improving the emulator's
handling of the BAO would be the most promising avenue for tightening the
overall distribution of error.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=\textwidth]{error_on_emulators/def_massless_curves}
  \caption[Default Massless Emulator Error Curves]{5000 error curves provided 
  by running the test set through the emulator. The curves are colored
  according to their value in $\tilde{\sigma}_{12}$.
  In absolute terms, the emulator
  clearly performs best on the small scales. In relative terms, the
  performance is about the same on large and small scales.
  Regardless of the metric used, the
  error is most extreme on medium scales, and drastic fluctuations can be seen 
  in the percent error plot.}
  \label{fig: def_massless_curves}
\end{figure}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=\textwidth]{error_on_emulators/def_massless_hist}
  \caption[Default Massless Emulator Error Histograms]{1000 error curves 
  	provided by running the test set through the emulator. The shapes
  	are broadly consistent with those seen in the massive case
  	(figure~\ref{fig: def_massive_hist}.}
  \label{fig: def_massless_hist}
\end{figure}

In figures~\ref{fig: def_massless_curves} and~\ref{fig: def_massless_hist},
we have included analogous plots from our massless-neutrino emulator.
The overall shape of the error curves appears similar to the massive
case, although here the absolute errors are small enough that fluctuations
in the BAO region can be clearly seen in both cases. Furthermore, the
percent error curves appear to be tightly concentrated both at small and
large $k$, whereas the spread towards large $k$ increased visibly
in the massive case. From the histograms we can appreciate that the error
distributions are roughly similar but the spread has been tightened in both
histograms by roughly a factor of two. By contrast, the percent error
curves have decreased in dynamic range by a factor of four.

The BAO fluctuations are proportionally much more significant here, suggesting
that the BAO errors are the most significant contributor to percent errors
across all cosmologies. This
further encourages future work to focus on BAO modeling, as both the massive-
and massless-neutrino emulators could benefit significantly.
\selfcomment{Create some plots focusing on the BAO error spikes? i.e.
zoom-in on k-ranges.}

The massive emulator clearly performs worse than its 
massless counterpart. The emulators are difficult to compare because they
were constructed from LHSs of different dimension: four in the massless case,
six in the massive case. Since $N_s = 5000$ is constant, we expect the 
massless LHS to sample the parameter space much more densely than the massive
LHS. In any case, the discrepancy in accuracies will be worsened by the
approximate nature of our fit from section~\ref{sec: proposed_fit}:
the results of section~\ref{sec: fit_testing} indicate
that evolution parameters besides $A_s$ are necessary for complete
characterization of the impact of massive neutrinos. Nevertheless, the
overall percent error of the massive emulator is comparable with that
of CAMB itself, so we consider the massive emulator a confirmation of the
techniques introduced in chapter~\ref{chap: A_s}.

\selfcomment{I plan to spend some time talking 
about \textit{why} parameter x is the current biggest problem for the 
emulator.}

\selfcomment{It would have been nice if you had done like Andrea said,
and produced a plot colored by the ``extremeness'' of the parameters. We
could implement an extremeness index for parameter $x$ simply by taking
subtracting 0.5 and taking the absolute value, assuming that $x$ comes from
the unit LHS. Then, we could take the average over six parameters to get
an extremeness index for the cosmology as a whole. Optionally, for plot
optimization, you could multiply the final value by 2 so that the extremeness
runs from 0 to 1.}


\section{Improvement from Two-emulator Solution}
\label{sec: 2emu_improvement}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=\textwidth]{error_on_emulators/two_emu_curves}
  \caption[Performance of Massive Emulator in Massless Case]{1000 error
  	curves provided
  	by running the massless-neutrino test set through the massive-neutrino 
  	emulator. The shape of both plots is significantly different from the
  	massive-emulator's test cosmologies shown in
  	figure~\ref{fig: def_massive_curves}. We therefore consider our
  	two-emulator solution strongly motivated.}
  \label{fig: two_emu_curves}
\end{figure}

To justify our use of a two-emulator solution to increase
accuracy in the massless-neutrino case, we task the massive-neutrino emulator 
with predictions over the test set of the massless-neutrino emulator.
To adjust the four-dimensional massless-neutrino test LHS to
the six-dimensional massive-neutrino emulator, we filled in
$A_s \approx 2.1272 \cdot 10^{-9}$ and $\omega_\nu = 0$ everywhere.
We consider
this a fair test because we sampled $\omega_\nu$ values for the
massive-neutrino emulator from a uniform distribution [0, 0.01]. Therefore,
in principle, the $\omega_\nu = 0$ case should only be a slight extrapolation.

The overall error of the massive emulator is larger, but this does not
explain all of the results that we see--these error curves also differ
significantly in shape, with increasingly aberrant behavior at large scales.
Also, the BAO feature seems to be slightly complicated by the presence of
massive neutrinos.

Now that we have used the massless-emulator test set to motivate our use of
a two-emulator solution, we move on from the massless emulator.
As evolution-mapping emulation for \textit{massive}-neutrino cosmologies
is the novel feature of this work, we will henceforth concentrate exclusively
on the massive-neutrino emulator.

\section{Minimum Separation of the Training LHC}
\label{sec: error_from_lhc}

% The following plots were generated with emu_experiment_histograms.ipynb
\begin{figure}[ht!]
    \begin{subfigure}{0.35 \textheight}
    \centering
 		\includegraphics[width=\textwidth]{error_on_emulators/deltas-hist-minsep}
 		\caption{Median absolute errors.}
 		\label{fig: minsep_experiment_deltas}
    \end{subfigure}
    \begin{subfigure}{0.35 \textheight}
    \centering
 		\includegraphics[width=\textwidth]{error_on_emulators/percents-hist-minsep}
 		\caption{Median absolute percent errors.}
 		\label{fig: minsep_experiment_percerr}
    \end{subfigure}
        \centering
    \caption[Impact of $s^*$ on Accuracy]
    		{Histograms of errors associated with emulators trained on LHSs of
    			different $s^*$ values. Despite the theoretical importance of
    			the quantity, its impact on the errors appears extremely limited.}
    \label{fig: minsep_experiment}
\end{figure}

The final training LHS had an $s^*$ of 0.07972 in the massive case and 
0.02274 in the massless case, rounded to four significant figures. In order
to quantitatively explore the impact of the LHS's $s^*$ on the performance
of the emulator, we created three additional emulators of different $s^*$
values and compared their performance using the test set for the default
emulator, which is also the one with the highest $s^*$.

In figure~\ref{fig: minsep_experiment}, we have prepared two histograms to
compare the errors from the four emulators. Surprisingly, $s^*$ does not
appear to affect the error distribution in any distinct way. As a further
step, we include tables~\ref{tab: minsep_experiment_delta_stats}
and~\ref{tab: minsep_experiment_percerr_stats}. None of the columns evolves
in a consistent manner, and so we call the experiment inconclusive.

% The following table was generated with emu_experiment_stats.ipynb
\begin{table}[ht!]
\centering
\begin{tabular}{l|l|l|l|l}
\hline
$s^*$ & Median of Means & Median of Medians & Median of STDs & Maximum PTP \\ \hline
$0.0545$ & 0.167753 & 0.045098 & 0.232575 & 205.656917 \\
$0.0629$ & 0.169627 & 0.044320 & 0.234392 & 174.772714 \\
$0.0713$ & 0.194701 & 0.050606 & 0.275545 & 203.590333 \\
$0.0797$ & 0.173023 & 0.044955 & 0.244320 & 224.434379 \\
\end{tabular}
	\cprotect\caption[$s^*$ Experiment: Percent Error Statistics]{Table of
		absolute error statistics
		when applying the default massless emulator's test
		set to emulators trained on LHSs of different $s^*$ values. In all
		columns, lower values indicate preferred outcomes. ``STD:'' standard
		deviation. ``PTP:'' peak-to-peak, or the difference in the maximum
		and minimum values. None of the columns shows a consistent trend.
		Only in the case of the median of medians is the last-row value
		lower than that of the first row.}
 \label{tab: minsep_experiment_delta_stats}
\end{table}

% The following table was generated with emu_experiment_stats.ipynb
\begin{table}[ht!]
\centering
\begin{tabular}{l|l|l|l|l}
\hline
$s^*$ & Median of Means & Median of Medians & Median of STDs & Maximum PTP \\ \hline
$0.0545$ & 0.002835 & 0.002240 & 0.002025 & 0.192945 \\
$0.0629$ & 0.002850 & 0.002179 & 0.002079 & 0.196711 \\
$0.0713$ & 0.003052 & 0.002409 & 0.002059 & 0.266151 \\
$0.0797$ & 0.002883 & 0.002255 & 0.002058 & 0.291348 \\
\end{tabular}
	\cprotect\caption[$s^*$ Experiment: Percent Error Statistics]{Table of
		absolute percent error statistics
		when applying the default massless emulator's test
		set to emulators trained on LHSs of different $s^*$ values. In all
		columns, lower values indicate preferred outcomes. ``STD:'' standard
		deviation. ``PTP:'' peak-to-peak, or the difference in the maximum
		and minimum values. None of the columns shows an expected trend.
		We consider it a coincidence that the maximum PTP in percent error
		\textit{increases} consistently with increasing $s^*$, especially
		since the corresponding column in the absolute errors
		(see table~\ref{tab: minsep_experiment_delta_stats}) lacks this
		trend.}
 \label{tab: minsep_experiment_percerr_stats}
\end{table}

As mentioned in section~\ref{sec: lhc}, we expected the errors to consistently
decrease with increasing $s^*$, as this quantity communicates the evenness of 
the coverage of the space of cosmologies.

The tested range in $s^*$ may have been too small for us to appreciate a
consistent impact. The scope of this experiment was limited by our approach
to generating LHCs, as the smallest and largest $s^*$ values tested came at
the cost of several days of computation time. Alternatively, we may have been
able to detect a consistent difference in the emulators by expanding the
testing set with many more cosmologies. For example, if we test over
30000 cosmologies (instead of the 5000 used here), we may find that noise in
our random selection of cosmologies obscures the effect of $s^*$.

Despite these two suggestions, we nevertheless conclude that the impact of
$s^*$ may be extremely weak, even if a higher $s^*$ value is theoretically
preferred. This suggests that our brute-force solution of randomly generating
LHSs is appropriate for our purposes.


\section{Resolution of the k Axis}
\label{sec: Nk_experiment}

\begin{figure}[ht!]
  \centering
  \includegraphics[scale=0.5]{error_on_emulators/percents-hist-N_k}
  \caption[Impact of $N_k$ on Accuracy]{Histogram of median percent errors
  	across all 5000 cosmologies tested. The test data are different for each
  	emulator but each test set contains 5000 spectra. We fail to observe any
  	meaningful connection between the value of $N_k$ and the shape of the
  	distribution.}
  \label{fig: Nk_experiment}
\end{figure}

To understand the impact of our choice of $N_k = 300$ for the emulator, we
also constructed and tested emulators for $N_k = 100$, 200, 400, and 500.
To control for interpolation error, each emulator has its own test set where
the test spectra have the same $N_k$. The
difference in test sets contributes random error that obscures the comparison.
We are interested in whether our GPR infrastructure is less efficient at
learning lower- than higher-resolution spectra.

The absolute errors cannot be directly compared across different emulators.
This is because the $N_k = 500$ emulator is tested at five times as many
points as the $N_k = 100$ emulator. Consequently, for this section, we focus
exclusively on percent errors.

In figure~\ref{fig: Nk_experiment}, we show a histogram of the median absolute
percent errors. The histograms are difficult to distinguish and do not admit
of an immediate preference for any $N_k$ value. Again, we produce a summary
of relevant statistics in table~\ref{tab: Nk_experiment_percerr_stats}. As
with our study of the impact of $s^*$, the values within each column do not
vary widely from each other, and do not confrom to any consistent trend.

% The following table was generated with emu_experiment_stats.ipynb
\begin{table}[ht!]
\centering
\begin{tabular}{l|l|l|l|l}
\hline
$N_k$ & Median of Means & Median of Medians & Median of STDs & Maximum PTP \\ \hline
$100$ & 0.003082 & 0.002427 & 0.002174 & 0.272042 \\
$200$ & 0.002878 & 0.002243 & 0.002054 & 0.297159 \\
$300$ & 0.002883 & 0.002255 & 0.002058 & 0.291348 \\
$400$ & 0.003034 & 0.002461 & 0.002042 & 0.277015 \\
$500$ & 0.002881 & 0.002221 & 0.002088 & 0.296367 \\
\end{tabular}
	\cprotect\caption[$N_k$ Experiment: Percent Error Statistics]{Table of
		absolute percent error statistics
		for emulators constructed with different $N_k$.
		The test data are different for each
  		emulator but each test set contains 5000 spectra.
		In all
		columns, lower values indicate preferred outcomes. ``STD:'' standard
		deviation. ``PTP:'' peak-to-peak, or the difference in the maximum
		and minimum values. None of the columns shows a consistent trend.
		In combination with the results of
		figure~\ref{fig: Nk_experiment}, these statistics suggest that
		$N_k$ does not significantly influence the performance of the
		emulator.} 
 \label{tab: Nk_experiment_percerr_stats}
\end{table}

Unlike with $s^*$, we lack a theoretical basis for believing $N_k$ to be a
quantity important to the performance of the emulator. Instead, the value of
$N_k$ should be modified by the user according to the use case. However, we
caution that our results here cannot be interpreted as conclusive evidence
against $N_k$'s relevance. Our inconclusive results from the $s^*$ experiment
suggest that our tests are not sufficiently thorough to establish a
hyperparameter's relevance, because in that case we have a strong theoretical
basis for the parameter's importance.

\section{Number of Training Samples}
\label{sec: num_samples}

As a final experiment, we study the impact of our choice of
$N_s = 5000$ on the accuracy of the emulator.
As with $s^*$, we expect to find an
unambiguous trend toward increasing accuracy with greater $N_s$ values.
We create new emulators to test the $N_s$ values 3000, 4000, 6000, and 7000.
All emulators use the same $N_s = 5000$ test set created for the default
emulator.

% The following plots were generated with emu_experiment_histograms.ipynb
\begin{figure}[ht!]
    \begin{subfigure}{0.35 \textheight}
    \centering
 		\includegraphics[width=\textwidth]{error_on_emulators/deltas-hist-N_s}
 		\caption{Median absolute errors.}
 		\label{fig: Ns_experiment_deltas}
    \end{subfigure}
    \begin{subfigure}{0.35 \textheight}
    \centering
 		\includegraphics[width=\textwidth]{error_on_emulators/percents-hist-N_s}
 		\caption{Median absolute percent errors.}
 		\label{fig: Ns_experiment_percerr}
    \end{subfigure}
        \centering
    \caption[Impact of $N_s$ on Accuracy]
    		{Histograms of errors associated with emulators trained on LHSs of
    			different $N_s$ values. In all cases, the test set is the same as
    			was used for the default emulator.
    			Unlike the previous experiments, we observe a consistent
    			trend toward tighter distributions for higher $N_s$ values.
    			Nonetheless, the trend is subtle.}
    \label{fig: Ns_experiment}
\end{figure}

In figures~\ref{fig: Ns_experiment_deltas}
and~\ref{fig: Ns_experiment_percerr} we include two histograms showing the
median absolute and absolute percent errors for each emulator. Although the
impact of $N_s$ is clear, the differences between the error distributions
are not dramatic.

% The following table was generated with emu_experiment_stats.ipynb
\begin{table}[ht!]
\centering
\begin{tabular}{l|l|l|l|l}
\hline
$N_s$ & Median of Means & Median of Medians & Median of STDs & Maximum PTP \\ \hline
$3000$ & 0.2382 & 0.0588 & 0.3388 & 175.5588 \\
$4000$ & 0.2010 & 0.0567 & 0.2741 & 185.5470 \\
$5000$ & 0.1730 & 0.0450 & 0.2443 & 224.4344 \\
$6000$ & 0.1712 & 0.0425 & 0.2415 & 146.6090 \\
$7000$ & 0.1633 & 0.0410 & 0.2305 & 118.7862 \\
\end{tabular}
	\cprotect\caption[$N_s$ Experiment: Deltas Statistics]{Table of
		absolute error statistics
		for emulators constructed with different $N_s$.
		The test data are the same in each case and given by the default
		massive test data.
		In all columns,
		lower values indicate preferred outcomes. ``STD:'' standard
		deviation. ``PTP:'' peak-to-peak, or the difference in the maximum
		and minimum values.
		All columns show monotonic improvement with increased $N_s$ except
		for the final column, which nonetheless shows a weaker trend of the
		same kind.}
 \label{tab: Ns_experiment_deltas_stats}
\end{table}

% The following table was generated with emu_experiment_stats.ipynb
\begin{table}[ht!]
\centering
\begin{tabular}{l|l|l|l|l}
\hline
$N_s$ & Median of Means & Median of Medians & Median of STDs & Maximum PTP \\ \hline
$3000$ & 0.0037 & 0.0030 & 0.0027 & 0.2794 \\
$4000$ & 0.0032 & 0.0026 & 0.0022 & 0.2305 \\
$5000$ & 0.0029 & 0.0023 & 0.0021 & 0.2913 \\
$6000$ & 0.0028 & 0.0022 & 0.0020 & 0.1893 \\
$7000$ & 0.0027 & 0.0021 & 0.0019 & 0.1189 \\
\end{tabular}
	\cprotect\caption[$N_s$ Experiment: Percent Error Statistics]{Table of
		absolute percent error statistics
		for emulators constructed with different $N_s$.
		The test data are the same in each case and given by the default
		massive test data.
		In all columns,
		lower values indicate preferred outcomes. ``STD:'' standard
		deviation. ``PTP:'' peak-to-peak, or the difference in the maximum
		and minimum values.
		All columns show monotonic improvement, although the gains are only
		dramatic in the final column. Consider, for example, that the
		addition of 1000 samples decreases the median median percent error
		by one part in ten thousand between the $N_s = 5000$ and 6000
		emulators and between the $N_s = 6000$ and 7000 emulators.}
 \label{tab: Ns_experiment_percerr_stats}
\end{table}

To display the differences in a somewhat more obvious format, we have again
produced tables of statistical aggregates over the same data sets. All of
the columns in tables~\ref{fig: Ns_experiment_deltas}
and~\ref{tab: Ns_experiment_percerr_stats} show expected trends except for
the maximum PTPs. We do not consider the lack of a trend in the final column
to be a cause for concern, as the metric is by nature volatile: it tracks only
the worst error curve in each group. We still consider the statistic
valuable as an easily-quotable result, because it immediately conveys the
worst error seen in 5000 test cases. Nevertheless, the volatility exposed by 
these tables provides useful perspective when interpreting the results of
sections~\ref{sec: error_from_lhc} and~\ref{sec: Nk_experiment}.

We also point out that the trends, while unambiguous, are surprisingly
subtle. Proportionally, for example, the median median percent error does
decrease by almost 50\%, but the value at $N_s=3000$ already falls well below
the error bounds of CAMB itself.
This suggests that the emulator error is already in a regime of
diminishing returns even by $N_s = 3000$. Future studies could extend this
investigation by building emulators with $N_s = 2000$ and lower.

However, for users concerned with worst-case performance regardless of its
rarity, increasing $N_s$ further may be worthwhile. Consider, for example,
that the worst-case error for the $N_s = 7000$ emulator spans a dynamic range
almost three times smaller than that for the $N_s = 3000$ emulator.

The results of this chapter lead us to suggest that the accuracies given for
our default emulator are broadly representative of the code's abilities, as
varying $s^*$, $N_k$, and $N_s$ do not significantly alter the comparability
of our errors with those of CAMB.
