{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc4f7cf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53aead2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 10:52:20.670796: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-16 10:52:20.828580: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import copy\n",
    "\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb8013",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccaaa659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4000 averages of 50\n",
    "# 4000 averages of 1000\n",
    "\n",
    "# Since we only need images from the dataset to encode and decode, we\n",
    "# won't use the labels.\n",
    "\n",
    "# 2000 training, 1000 validation, 1000 test\n",
    "_train_noisy, _val_noisy, _test_noisy = \\\n",
    "    data.loadData_tri(ns=50, N_train=2000, N_val=1000, N_test=1000)\n",
    "_train_target, _val_target, _test_target = \\\n",
    "    data.loadData_tri(ns=1000, N_train=2000,  N_val=1000, N_test=1000)\n",
    "\n",
    "theory_cov = np.loadtxt(\"samples2/xi_new_boss_zs_z0p61_lin_ximulti_covar.dat\")\n",
    "\n",
    "# Normalize and reshape the data\n",
    "train_noisy = data.preprocess_cov(_train_noisy, theory_cov=theory_cov)\n",
    "val_noisy = data.preprocess_cov(_val_noisy, theory_cov=theory_cov)\n",
    "test_noisy = data.preprocess_cov(_test_noisy, theory_cov=theory_cov)\n",
    "\n",
    "train_target = data.preprocess_cov(_train_target, theory_cov=theory_cov)\n",
    "val_target = data.preprocess_cov(_val_target, theory_cov=theory_cov)\n",
    "test_target = data.preprocess_cov(_test_target, theory_cov=theory_cov)\n",
    "\n",
    "#target_data = preprocess_theory(theory_cov)\n",
    "\n",
    "# Display the train data and a version of it with added noise\n",
    "# display(train_data, train_data)\n",
    "\n",
    "cov_len = len(theory_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78957b33",
   "metadata": {},
   "source": [
    "## Build the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2528d158-c345-497e-9159-3c2b0541344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Technically Keras already provides this,\n",
    "but the API is a mess when it comes to\n",
    "the layer / activation function distinction\"\"\"\n",
    "from tensorflow.keras import backend as K\n",
    "def ReLU(x):\n",
    "    return K.relu(x, alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff32614e-11a4-4f5c-91f0-f9d12cd120c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aliases to keep the code compact\n",
    "universal_kernel = (3, 3)\n",
    "universal_padding = \"same\"\n",
    "universal_dropRate = 0.05\n",
    "universal_numStrides = 1\n",
    "\n",
    "def conv(in_, filters, activation_in):\n",
    "    return layers.Conv2D(filters, universal_kernel,\n",
    "        activation=activation_in, padding=universal_padding)(in_)\n",
    "\n",
    "def tConv(in_, filters, activation_in):\n",
    "    return layers.Conv2DTranspose(filters, universal_kernel,\n",
    "        strides=universal_numStrides, activation=activation_in,\n",
    "        padding=universal_padding)(in_)\n",
    "\n",
    "def drop(in_):\n",
    "    return tf.keras.layers.Dropout(universal_dropRate)(in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c89170f-6698-4863-ae35-f435523f731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=(cov_len, cov_len, 1))\n",
    "\n",
    "def get_autoencoders(function):\n",
    "    print(\"Initializing self autoencoder...\")\n",
    "    \n",
    "    a_self = Model(input_, function)\n",
    "    a_self.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    a_self.fit(\n",
    "        x=train_noisy,\n",
    "        y=train_noisy,\n",
    "        epochs=5,\n",
    "        batch_size=15,\n",
    "        shuffle=True,\n",
    "        validation_data=(val_noisy, val_noisy),\n",
    "    )\n",
    "    \n",
    "    print(\"Initializing target autoencoder...\")\n",
    "    \n",
    "    a_target = Model(input_, function)\n",
    "    a_target.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    \n",
    "    a_target.fit(\n",
    "        x=train_noisy,\n",
    "        y=train_target,\n",
    "        epochs=5,\n",
    "        batch_size=15,\n",
    "        shuffle=True,\n",
    "        validation_data=(val_noisy, val_target),\n",
    "    )\n",
    "    \n",
    "    return a_self, a_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2ac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 10:52:36.300169: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Old function:\n",
      "Initializing self autoencoder...\n",
      "Epoch 1/5\n",
      "134/134 [==============================] - 33s 245ms/step - loss: 0.0741 - val_loss: 0.0707\n",
      "Epoch 2/5\n",
      "134/134 [==============================] - 36s 266ms/step - loss: 0.0705 - val_loss: 0.0710\n",
      "Epoch 3/5\n",
      "134/134 [==============================] - 37s 273ms/step - loss: 0.0711 - val_loss: 0.0711\n",
      "Epoch 4/5\n",
      "134/134 [==============================] - 36s 268ms/step - loss: 0.0709 - val_loss: 0.0711\n",
      "Epoch 5/5\n",
      "134/134 [==============================] - 36s 268ms/step - loss: 0.0709 - val_loss: 0.0711\n",
      "Initializing target autoencoder...\n",
      "Epoch 1/5\n",
      "134/134 [==============================] - 37s 276ms/step - loss: 0.0485 - val_loss: 0.0485\n",
      "Epoch 2/5\n",
      "134/134 [==============================] - 36s 269ms/step - loss: 0.0485 - val_loss: 0.0485\n",
      "Epoch 3/5\n",
      "134/134 [==============================] - 36s 268ms/step - loss: 0.0485 - val_loss: 0.0485\n",
      "Epoch 4/5\n",
      "134/134 [==============================] - 36s 268ms/step - loss: 0.0485 - val_loss: 0.0485\n",
      "Epoch 5/5\n",
      "134/134 [==============================] - 37s 274ms/step - loss: 0.0485 - val_loss: 0.0485\n",
      "\n",
      "\n",
      "Paper's function:\n",
      "Initializing self autoencoder...\n",
      "Epoch 1/5\n",
      "134/134 [==============================] - 61s 456ms/step - loss: 0.0056 - val_loss: 9.8369e-04\n",
      "Epoch 2/5\n",
      " 92/134 [===================>..........] - ETA: 17s - loss: 0.0012"
     ]
    }
   ],
   "source": [
    "def build_layers(inner_act, last_act, drops=True):\n",
    "    # Encoder\n",
    "    x = conv(input_, 64, last_act)\n",
    "    if drops:\n",
    "        x = drop(x)\n",
    "    x = conv(x, 32, inner_act)\n",
    "    if drops:\n",
    "        x = drop(x)\n",
    "    # Decoder\n",
    "    x = tConv(x, 32, inner_act)\n",
    "    if drops:\n",
    "        x = drop(x)\n",
    "    x = tConv(x, 64, inner_act)\n",
    "    if drops:\n",
    "        x = drop(x)\n",
    "    x = conv(x, 1, last_act)\n",
    "    return x\n",
    "\n",
    "old = build_layers(\"relu\", \"sigmoid\", drops=False)\n",
    "paper = build_layers(ReLU, \"tanh\", drops=True)\n",
    "nondropper = build_layers(ReLU, \"tanh\", drops=False)\n",
    "sigmoidLast = build_layers(ReLU, \"sigmoid\", drops=True)\n",
    "nonleaker = build_layers(\"relu\", \"tanh\", drops=True)\n",
    "\n",
    "# Autoencoder\n",
    "print(\"\\n\\nOld function:\")\n",
    "a_old_self, a_old_target = get_autoencoders(old)\n",
    "\n",
    "print(\"\\n\\nPaper's function:\")\n",
    "a_paper_self, a_paper_target = get_autoencoders(paper)\n",
    "\n",
    "print(\"\\n\\nNondropper function:\")\n",
    "a_nondropper_self, a_nondropper_target = get_autoencoders(nondropper)\n",
    "\n",
    "print(\"\\n\\nSigmoid as last activation function:\")\n",
    "a_sigmoidLast_self, a_sigmoidLast_target = get_autoencoders(sigmoidLast)\n",
    "\n",
    "print(\"\\n\\nNonleaker function:\")\n",
    "a_nonleaker_self, a_nonleaker_target = get_autoencoders(nonleaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98359b47-db0b-4aae-b186-ed767a3ac2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_noisy[0].reshape(cov_len, cov_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a5a1be",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d227db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = a_paper_target.predict(val_noisy)\n",
    "plt.imshow(predictions[0].reshape(cov_len, cov_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81634c1-7fac-4d89-bd7e-fc40b7df7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = a_paper_target.predict(test_noisy)\n",
    "plt.imshow(predictions[0].reshape(cov_len, cov_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837cd671-7b69-4d4b-acbb-7ccbcfe3c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "a_old_self, a_old_target = get_autoencoders(old)\n",
    "a_paper_self, a_paper_target = get_autoencoders(paper)\n",
    "a_nondropper_self, a_nondropper_target = get_autoencoders(nondropper)\n",
    "a_sigmoidLast_self, a_sigmoidLast_target = get_autoencoders(sigmoidLast)\n",
    "a_nonleaker_self, a_nonleaker_target = get_autoencoders(nonleaker)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "a_old_self.save(\"a_old_self\")\n",
    "a_old_target.save(\"a_old_target\")\n",
    "a_paper_self.save(\"a_paper_self\")\n",
    "a_paper_target.save(\"a_paper_target\")\n",
    "a_nondropper_self.save(\"a_nondropper_self\")\n",
    "a_nondropper_target.save(\"a_nondropper_target\")\n",
    "a_sigmoidLast_self.save(\"a_sigmoidLast_self\")\n",
    "a_sigmoidLast_target.save(\"a_sigmoidLast_target\")\n",
    "a_nonleaker_self.save(\"a_nonleaker_self\")\n",
    "a_nonleaker_target.save(\"a_nonleaker_target\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37b686-c730-4597-896b-fba86810d75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "23262661808f7a123023321b882c61e6062caf1b3faf8a2c27cc43e1b4060f86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
